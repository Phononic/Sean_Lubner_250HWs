{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1) Make a DataFrame with one row per issue with the following columns extracted\n",
      "from the issue data:\n",
      "\n",
      "   ``ntitle, created_at, labels, closed_at, user, id``\n",
      "\n",
      "Transform the user values to be simply the 'login' string, so that the user\n",
      "column contains only string usernames.\n",
      "\n",
      "2) Remove duplicate rows by id from the DataFrame you just created using the id\n",
      "column's duplicated method.\n",
      "\n",
      "4) Convert the ``created_at`` and ``closed_at columns`` from string to datetime type.\n",
      "\n",
      "5) Now construct appropriate time series and pandas functions to make the\n",
      "following plots:\n",
      "\n",
      "- Number of issues created by month\n",
      "\n",
      "- Number of distinct users creating issues each month (hint: you can pass a\n",
      "  function to resample's how argument, and there's nothing wrong with having\n",
      "  string values in a TimeSeries)\n",
      "\n",
      "6) Make a table and an accompanying plot illustrating:\n",
      "\n",
      "- The mean number of days it took for issues to be closed by the month they\n",
      "  were opened. In other words, for closed issues created in August 2012, how\n",
      "  long were they open on average? (hint: use the ``total_seconds`` function on the\n",
      "  timedelta objects computed when subtracting datetime objects). Also show the\n",
      "  number of issues in each month in the table.\n",
      "\n",
      "7) Make a DataFrame containing all the comments for all of the issues. You will\n",
      "want to add an ``id`` attribute to each comment while doing so so that each row\n",
      "contains a single comment and has the id of the issue it belongs to.\n",
      "\n",
      "Convert the ``created`` column to datetime format; note you will need to multiply\n",
      "the values (appropriately converted to integers) by 1000000 to get them in\n",
      "nanoseconds and pass to to_datetime.\n",
      "\n",
      "8) For each month, compute a table summarizing the following for each month:\n",
      "\n",
      "- Total number of issue comments\n",
      "- The \"chattiest\" user (most number of comments)\n",
      "- The percentage of total comments made by the chattiest users\n",
      "- The number of distinct participants in the issue comments\n",
      "\n",
      "9) Create a helper ``labels`` table from the issues data with two columns: id and\n",
      "label. If an issue has 3 elements in its 'labels' value, add 3 rows to the\n",
      "table. If an issue does not have any labels, place a single row with None as\n",
      "the label (hint: construct a list of tuples, then make the DataFrame).\n",
      "\n",
      "10) Now, join the issues data with the labels helper table (pandas.merge). Add\n",
      "a column to this table containing the number of days (as a floating point\n",
      "number) it took to close each issue.\n",
      "\n",
      "11) Compute a table containing the average time to close for each label\n",
      "type. Now make a plot comparing mean time to close by month for Enhancement\n",
      "versus Bug issue types."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Homework 7\n",
      "------\n",
      "Sean Lubner"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1) Make a DataFrame with one row per issue with the following columns extracted\n",
      "from the issue data:\n",
      "\n",
      "   ``ntitle, created_at, labels, closed_at, user, id``\n",
      "\n",
      "Transform the user values to be simply the 'login' string, so that the user\n",
      "column contains only string usernames."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "df_raw = pd.read_json('/Users/sean/Desktop/closed.json', convert_dates = ['created_at', 'closed_at'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create a dataframe with the desired columns\n",
      "df = pd.concat([df_raw.title, df_raw.created_at, df_raw.labels, df_raw.closed_at, df_raw.user, df_raw.id], \n",
      "                   axis=1, keys=['title', 'created_at', 'labels', 'closed_at', 'user', 'id'])\n",
      "df = pd.DataFrame(df)\n",
      "df.set_index('created_at', inplace=True)\n",
      "df.user = df.user.apply(lambda x: x['login'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "2) Remove duplicate rows by id from the DataFrame you just created using the id column's duplicated method."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Remove duplicates (note: duplicated marks duplicate items as \"True\"\n",
      "df = df[[not x for x in df.id.duplicated()]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "length before removing duplicates: 2968\n",
        "length after removing duplicates: 2934\n"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "delta_t_per_issue = df.created_at - df.closed_at\n",
      "print type(delta_t_per_issue[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ids = df.id\n",
      "print 'original length:', len(ids)\n",
      "print 'number of uniques:', len(ids.unique())\n",
      "df.id.duplicated?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "original length: 2968\n",
        "number of uniques: 2934\n"
       ]
      }
     ],
     "prompt_number": 36
    }
   ],
   "metadata": {}
  }
 ]
}