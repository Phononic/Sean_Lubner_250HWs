{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pickle\n",
      "from skimage.feature import peak_local_max as plm\n",
      "from skimage.filter import vsobel, hsobel\n",
      "from os import listdir\n",
      "from pylab import imread\n",
      "from time import time\n",
      "\n",
      "validation_directory = '/new/directory/path/' # put the path to the validation directory here (or call with it explicitly)\n",
      "\n",
      "def extract_features(image_path_list):\n",
      "    feature_list = []\n",
      "    target_list = []\n",
      "    k = 100 # number of evenly spaced percentage announcements (should be <= 100)\n",
      "    print(\"\\tFeature extraction completion:\")\n",
      "    announcements = [(i+1)*len(image_path_list)/k for i in range(k)]\n",
      "    for i, image_path in enumerate(image_path_list):\n",
      "        image_array = imread(image_path)\n",
      "        category = image_path.split('/')[-2]\n",
      "        target_list.append(category) # target = name of category\n",
      "        feature_list.append([feature_1(image_array), # image size\n",
      "                             feature_2(image_array), # mean red-channel\n",
      "                             feature_3(image_array), # mean green-channel\n",
      "                             feature_4(image_array), # mean blue-channel\n",
      "                             feature_5(image_array), # mean luminosity\n",
      "                             feature_6(image_array), # median luminosity\n",
      "                             feature_7(image_array), # standard deviation luminosity\n",
      "                             feature_8(image_array), # median red-channel\n",
      "                             feature_9(image_array), # median green-channel\n",
      "                             feature_10(image_array), # median blue-channel\n",
      "                             feature_11(image_array), # standard deviation red-channel\n",
      "                             feature_12(image_array), # standard deviation green-channel\n",
      "                             feature_13(image_array), # standard deviation blue-channel\n",
      "                             feature_14(image_array), # mean luminosity of vertical edge map\n",
      "                             feature_15(image_array), # median luminosity of vertical edge map\n",
      "                             feature_16(image_array), # standard deviation luminosity of vertical edge map\n",
      "                             feature_17(image_array), # mean luminosity of horizontal edge map\n",
      "                             feature_18(image_array), # median luminosity of horizontal edge map\n",
      "                             feature_19(image_array), # standard deviation luminosity of horizontal edge map\n",
      "                             feature_20(image_array), # pixels above threshold lum for horizontal edge map\n",
      "                             feature_21(image_array), # pixels above threshold lum for vertical edge map\n",
      "                             feature_22(image_array), # aspect ratio of image\n",
      "                             feature_23(image_array) # number of image peaks\n",
      "                             ])\n",
      "        \n",
      "        # Give the user progress updates regarding how far along feature extraction is (only works if not parallel)\n",
      "        if (i+1) in announcements:\n",
      "            print(\"{0:.0f}%...\".format(100.0*i/len(image_path_list))),\n",
      "    print('')\n",
      "    return ( np.array(feature_list), np.array(target_list) ) # easier indexing\n",
      "\n",
      "#--------------------------------- Start Features list ---------------------------------\n",
      "def feature_1(image_array):\n",
      "    \"\"\" Return the size of the image, in pixels \"\"\"\n",
      "    return image_array.size\n",
      "\n",
      "def feature_2(image_array):\n",
      "    \"\"\" Return the average red-channel value for the picture (in 0-255 scale) \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        return image_array[:,:,0].mean()\n",
      "    else:\n",
      "        return image_array.mean()\n",
      "\n",
      "def feature_3(image_array):\n",
      "    \"\"\" Return the average blue-channel value for the picture (in 0-255 scale) \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        return image_array[:,:,1].mean()\n",
      "    else:\n",
      "        return image_array.mean()\n",
      "\n",
      "def feature_4(image_array):\n",
      "    \"\"\" Return the average green-channel value for the picture (in 0-255 scale) \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        return image_array[:,:,2].mean()\n",
      "    else:\n",
      "        return image_array.mean()\n",
      "\n",
      "def feature_5(image_array):\n",
      "    \"\"\" Return the average luminosity value for the picture (in 0-255 scale) \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        return image_array.mean(axis=2).mean()\n",
      "    else:\n",
      "        return image_array.mean()\n",
      "\n",
      "def feature_6(image_array):\n",
      "    \"\"\" Returns the median pixels luminosity \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        image_array = image_array.mean(axis=2)\n",
      "    return np.median(image_array)\n",
      "\n",
      "def feature_7(image_array):\n",
      "    \"\"\" Returns the standard deviation of the pixels' luminosity \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        image_array = image_array.mean(axis=2)\n",
      "    return np.std(image_array)\n",
      "\n",
      "def feature_8(image_array):\n",
      "    \"\"\" Return the median red-channel value for the picture (in 0-255 scale) \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        return np.median(image_array[:,:,0])\n",
      "    else:\n",
      "        return np.median(image_array)\n",
      "\n",
      "def feature_9(image_array):\n",
      "    \"\"\" Return the median blue-channel value for the picture (in 0-255 scale) \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        return np.median(image_array[:,:,1])\n",
      "    else:\n",
      "        return np.median(image_array)\n",
      "\n",
      "def feature_10(image_array):\n",
      "    \"\"\" Return the median green-channel value for the picture (in 0-255 scale) \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        return np.median(image_array[:,:,2])\n",
      "    else:\n",
      "        return np.median(image_array)\n",
      "\n",
      "def feature_11(image_array):\n",
      "    \"\"\" Return the standard deviation of the red-channel value for the picture (in 0-255 scale) \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        return np.std(image_array[:,:,0])\n",
      "    else:\n",
      "        return np.std(image_array)\n",
      "\n",
      "def feature_12(image_array):\n",
      "    \"\"\" Return the the standard deviation of the blue-channel value for the picture (in 0-255 scale) \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        return np.std(image_array[:,:,1])\n",
      "    else:\n",
      "        return np.std(image_array)\n",
      "\n",
      "def feature_13(image_array):\n",
      "    \"\"\" Return the the standard deviation of the green-channel value for the picture (in 0-255 scale) \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        return np.std(image_array[:,:,2])\n",
      "    else:\n",
      "        return np.std(image_array)\n",
      "\n",
      "def feature_14(image_array):\n",
      "    \"\"\" Return the average luminosity for vertical edges map \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        image_array = image_array.mean(axis=2)\n",
      "    return np.mean(vsobel(image_array))\n",
      "\n",
      "def feature_15(image_array):\n",
      "    \"\"\" Returns the median luminosity for vertical edges map \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        image_array = image_array.mean(axis=2)\n",
      "    return np.median(vsobel(image_array))\n",
      "\n",
      "def feature_16(image_array):\n",
      "    \"\"\" Returns the standard deviation of the luminosity for vertical edges map \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        image_array = image_array.mean(axis=2)\n",
      "    return np.std(vsobel(image_array))\n",
      "\n",
      "def feature_17(image_array):\n",
      "    \"\"\" Return the average luminosity for horizontal edges map \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        image_array = image_array.mean(axis=2)\n",
      "    return np.mean(hsobel(image_array))\n",
      "\n",
      "def feature_18(image_array):\n",
      "    \"\"\" Returns the median luminosity for horizontal edges map \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        image_array = image_array.mean(axis=2)\n",
      "    return np.median(hsobel(image_array))\n",
      "\n",
      "def feature_19(image_array):\n",
      "    \"\"\" Returns the standard deviation of the luminosity for horizontal edges map \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        image_array = image_array.mean(axis=2)\n",
      "    return np.std(hsobel(image_array))\n",
      "\n",
      "def feature_20(image_array):\n",
      "    \"\"\" Returns the fraction of pixels above a threshold of the luminosity \n",
      "    for the horizontal edges map \"\"\"\n",
      "    thresh = 20 # Based on looking at histograms of edge maps of pictures\n",
      "    if len(image_array.shape) == 3:\n",
      "        image_array = image_array.mean(axis=2)\n",
      "    h_edge = hsobel(image_array)\n",
      "    return 1.0*sum(h_edge >= thresh)/h_edge.size\n",
      "\n",
      "def feature_21(image_array):\n",
      "    \"\"\" Returns the fraction of pixels above a threshold of the luminosity \n",
      "    for the vertical edges map \"\"\"\n",
      "    thresh = 20 # Based on looking at histograms of edge maps of pictures\n",
      "    if len(image_array.shape) == 3:\n",
      "        image_array = image_array.mean(axis=2)\n",
      "    v_edge = vsobel(image_array)\n",
      "    return 1.0*sum(v_edge >= thresh)/v_edge.size\n",
      "\n",
      "def feature_22(image_array):\n",
      "    \"\"\" Returns the aspect ratio of the image \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        image_array = image_array.mean(axis=2)\n",
      "    (height, width) = image_array.shape\n",
      "    return 1.0*height/width\n",
      "\n",
      "def feature_23(image_array):\n",
      "    \"\"\" Returns the number of image peaks \"\"\"\n",
      "    return len(plm(image_array, min_distance=50))\n",
      "#--------------------------------- End Features list ---------------------------------\n",
      "\n",
      "def collect_paths(imDirectory=validation_directory):\n",
      "    \"\"\" Given a validation directory, returns a list of image path strings for that directory.  Assumes\n",
      "        no sub-folders within the directory; just image files. \"\"\"\n",
      "    image_paths = []\n",
      "    image_names = listdir(imDirectory)\n",
      "    for name in image_names:\n",
      "        if name[0] != '.':\n",
      "            image_paths.append(imDirectory + \"/\" + name)\n",
      "        else:\n",
      "            print \"bad image '\" + name +\"' was skipped!\"\n",
      "    return image_paths\n",
      "\n",
      "def generate_feature_set(image_paths):\n",
      "    print \"\\t Now beginning Feature extraction...\"\n",
      "    before_extraction = time()\n",
      "    features = extract_features(image_paths)\n",
      "    after_extraction = time()\n",
      "    #pickle.dump( features, open( \"extracted_features_2.p\", \"wb\" ) )\n",
      "    print(\"Feature extraction complete after {0:.2f} seconds, or {1:.4f} seconds per image, for {2:.0f} total images.\"\\\n",
      "          .format(after_extraction-before_extraction,(after_extraction-before_extraction)/float(len(image_paths)),\n",
      "                  len(image_paths)))\n",
      "    print(\"Feature set contains {0:.0f} instances, each with {1:.0f} features.\".format(features[0].shape[0], features[0].shape[1]))\n",
      "    print(\"Target set contains {0:.0f} unique classes.\".format(len(np.unique(features[1]))))\n",
      "\n",
      "#--------------------------------- Classifiers ---------------------------------\n",
      "# load data\n",
      "im_data = pickle.load( open( \"extracted_features.p\", \"rb\" ) )\n",
      "X = im_data[0] # extracted features\n",
      "Y = im_data[1] # target\n",
      "num_classes = len(np.unique(Y)) # number of classes\n",
      "nc = X.shape[1]\n",
      "\n",
      "# optimize number of features\n",
      "parameters = {'max_features':map(lambda x: int(x), [np.ceil(np.sqrt(nc)), np.ceil(nc/3.0), np.ceil(nc/1.5)]),\n",
      "              'n_estimators':[50], 'compute_importances':[True], 'n_jobs':[1]}\n",
      "rf_opt = grid_search.GridSearchCV(RandomForestClassifier(), parameters,\\\n",
      "                                   score_func=metrics.accuracy_score, n_jobs = 1, cv = 4)\n",
      "before_GS = time()\n",
      "rf_opt.fit(X, Y)\n",
      "after_GS = time()\n",
      "best_rf = rf_opt.best_estimator_\n",
      "\n",
      "# ------------------- Output -------------------\n",
      "class feature_priority(object):\n",
      "    def __init__(self, priorities, dec=4):\n",
      "        self.feature_names = ['pixel count','avg red','avg green','avg blue','avg lum',\n",
      "                              'median lum','std lum','median red','median green','median blue',\n",
      "                              'std red','std green','std blue','avg lum v-edges','median lum v-edges',\n",
      "                              'std lum v-edges','avg lum h-edges','median lum h-edges','std h-edges',\n",
      "                              '>thresh h-edges','>thresh v-edges','aspect ratio','image peaks']\n",
      "        self.feature_priorities = map(lambda x: np.round(x, decimals=dec), priorities)\n",
      "        self.sorted_feats = sorted(zip(self.feature_names,self.feature_priorities), key = lambda x: x[1], reverse=True)\n",
      "    \n",
      "    def __str__(self):\n",
      "        outstr = \"Features (most to least important): \\n\"\n",
      "        for (i,j) in self.sorted_feats:\n",
      "            outstr += \"\\t\" + i + \" \"*(25-len(i)) + \"relative importance: \" + str(j) + \"\\n\"\n",
      "        return outstr\n",
      "\n",
      "class prediction_output(object):\n",
      "    def __init__(self, classifier, X, Y):\n",
      "        self.Y_pred = classifier.predict(X)\n",
      "        \n",
      "print(\"Time to run grid search: {0:.3f} sec.  Average of {1:.4f} sec per classifier fit/predict cycle (per parameter combo per CV-fold)\\n\"\\\n",
      "      .format(after_GS-before_GS, (after_GS-before_GS)/(len(rf_opt.grid_scores_)*rf_opt.cv)))\n",
      "print(\"Best score: {0:.2f}% accuracy, vs. random guessing at: {1:.2f}%, for a factor of {2:.1f}X improvement.\" \\\n",
      "      .format(100*rf_opt.best_score_, 100.0/num_classes, rf_opt.best_score_*num_classes))\n",
      "print(\"Best Parameters:\" + str(rf_opt.best_params_) + \"\\n\")\n",
      "\n",
      "feats = feature_priority(best_rf.feature_importances_)\n",
      "print str(feats)\n",
      "print \"Grid Search Scores:\" \n",
      "for score in rf_opt.grid_scores_:\n",
      "    print score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}