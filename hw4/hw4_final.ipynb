{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# imports\n",
      "import numpy as np\n",
      "import pickle\n",
      "from skimage.feature import peak_local_max as plm\n",
      "from skimage.filter import vsobel, hsobel\n",
      "from os import listdir\n",
      "from pylab import imread\n",
      "from time import time\n",
      "\n",
      "def extract_features(image_path_list):\n",
      "    \"\"\" Given a list of directories to image files, extract features from images and return a single\n",
      "        numpy array containing those features, appropriately formatted for classifier prediction. \"\"\"\n",
      "    feature_list = []\n",
      "    k = 100 # number of evenly spaced percentage announcements (should be <= 100)\n",
      "    print(\"     Feature extraction completion:\")\n",
      "    announcements = [(i+1)*len(image_path_list)/k for i in range(k)] # Announce the % complete to the user at these points\n",
      "    for i, image_path in enumerate(image_path_list):\n",
      "        image_array = imread(image_path)\n",
      "        feature_list.append([feature_1(image_array), # image size\n",
      "                             feature_2(image_array), # mean red-channel\n",
      "                             feature_3(image_array), # mean green-channel\n",
      "                             feature_4(image_array), # mean blue-channel\n",
      "                             feature_5(image_array), # mean luminosity\n",
      "                             feature_6(image_array), # median luminosity\n",
      "                             feature_7(image_array), # standard deviation luminosity\n",
      "                             feature_8(image_array), # median red-channel\n",
      "                             feature_9(image_array), # median green-channel\n",
      "                             feature_10(image_array), # median blue-channel\n",
      "                             feature_11(image_array), # standard deviation red-channel\n",
      "                             feature_12(image_array), # standard deviation green-channel\n",
      "                             feature_13(image_array), # standard deviation blue-channel\n",
      "                             feature_14(image_array), # mean luminosity of vertical edge map\n",
      "                             feature_15(image_array), # median luminosity of vertical edge map\n",
      "                             feature_16(image_array), # standard deviation luminosity of vertical edge map\n",
      "                             feature_17(image_array), # mean luminosity of horizontal edge map\n",
      "                             feature_18(image_array), # median luminosity of horizontal edge map\n",
      "                             feature_19(image_array) ])#, # standard deviation luminosity of horizontal edge map\n",
      "                            # feature_20(image_array), # pixels above threshold lum for horizontal edge map\n",
      "                            # feature_21(image_array), # pixels above threshold lum for vertical edge map\n",
      "                            # feature_22(image_array), # aspect ratio of image\n",
      "                            # feature_23(image_array) # number of image peaks\n",
      "                            # ])\n",
      "        \n",
      "        # Give the user progress updates regarding how far along feature extraction is (only works if not parallel)\n",
      "        if (i+1) in announcements:\n",
      "            print(\"{0:.0f}%...\".format(100.0*i/len(image_path_list))),\n",
      "    print('')\n",
      "    return np.array(feature_list) # easier indexing\n",
      "\n",
      "#--------------------------------- Start Features list ---------------------------------\n",
      "def feature_1(image_array):\n",
      "    \"\"\" Return the size of the image, in pixels \"\"\"\n",
      "    return image_array.size\n",
      "\n",
      "def feature_2(image_array):\n",
      "    \"\"\" Return the average red-channel value for the picture (in 0-255 scale) \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        return image_array[:,:,0].mean()\n",
      "    else:\n",
      "        return image_array.mean()\n",
      "\n",
      "def feature_3(image_array):\n",
      "    \"\"\" Return the average blue-channel value for the picture (in 0-255 scale) \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        return image_array[:,:,1].mean()\n",
      "    else:\n",
      "        return image_array.mean()\n",
      "\n",
      "def feature_4(image_array):\n",
      "    \"\"\" Return the average green-channel value for the picture (in 0-255 scale) \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        return image_array[:,:,2].mean()\n",
      "    else:\n",
      "        return image_array.mean()\n",
      "\n",
      "def feature_5(image_array):\n",
      "    \"\"\" Return the average luminosity value for the picture (in 0-255 scale) \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        return image_array.mean(axis=2).mean()\n",
      "    else:\n",
      "        return image_array.mean()\n",
      "\n",
      "def feature_6(image_array):\n",
      "    \"\"\" Returns the median pixels luminosity \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        image_array = image_array.mean(axis=2)\n",
      "    return np.median(image_array)\n",
      "\n",
      "def feature_7(image_array):\n",
      "    \"\"\" Returns the standard deviation of the pixels' luminosity \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        image_array = image_array.mean(axis=2)\n",
      "    return np.std(image_array)\n",
      "\n",
      "def feature_8(image_array):\n",
      "    \"\"\" Return the median red-channel value for the picture (in 0-255 scale) \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        return np.median(image_array[:,:,0])\n",
      "    else:\n",
      "        return np.median(image_array)\n",
      "\n",
      "def feature_9(image_array):\n",
      "    \"\"\" Return the median blue-channel value for the picture (in 0-255 scale) \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        return np.median(image_array[:,:,1])\n",
      "    else:\n",
      "        return np.median(image_array)\n",
      "\n",
      "def feature_10(image_array):\n",
      "    \"\"\" Return the median green-channel value for the picture (in 0-255 scale) \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        return np.median(image_array[:,:,2])\n",
      "    else:\n",
      "        return np.median(image_array)\n",
      "\n",
      "def feature_11(image_array):\n",
      "    \"\"\" Return the standard deviation of the red-channel value for the picture (in 0-255 scale) \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        return np.std(image_array[:,:,0])\n",
      "    else:\n",
      "        return np.std(image_array)\n",
      "\n",
      "def feature_12(image_array):\n",
      "    \"\"\" Return the the standard deviation of the blue-channel value for the picture (in 0-255 scale) \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        return np.std(image_array[:,:,1])\n",
      "    else:\n",
      "        return np.std(image_array)\n",
      "\n",
      "def feature_13(image_array):\n",
      "    \"\"\" Return the the standard deviation of the green-channel value for the picture (in 0-255 scale) \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        return np.std(image_array[:,:,2])\n",
      "    else:\n",
      "        return np.std(image_array)\n",
      "\n",
      "def feature_14(image_array):\n",
      "    \"\"\" Return the average luminosity for vertical edges map \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        image_array = image_array.mean(axis=2)\n",
      "    return np.mean(vsobel(image_array))\n",
      "\n",
      "def feature_15(image_array):\n",
      "    \"\"\" Returns the median luminosity for vertical edges map \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        image_array = image_array.mean(axis=2)\n",
      "    return np.median(vsobel(image_array))\n",
      "\n",
      "def feature_16(image_array):\n",
      "    \"\"\" Returns the standard deviation of the luminosity for vertical edges map \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        image_array = image_array.mean(axis=2)\n",
      "    return np.std(vsobel(image_array))\n",
      "\n",
      "def feature_17(image_array):\n",
      "    \"\"\" Return the average luminosity for horizontal edges map \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        image_array = image_array.mean(axis=2)\n",
      "    return np.mean(hsobel(image_array))\n",
      "\n",
      "def feature_18(image_array):\n",
      "    \"\"\" Returns the median luminosity for horizontal edges map \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        image_array = image_array.mean(axis=2)\n",
      "    return np.median(hsobel(image_array))\n",
      "\n",
      "def feature_19(image_array):\n",
      "    \"\"\" Returns the standard deviation of the luminosity for horizontal edges map \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        image_array = image_array.mean(axis=2)\n",
      "    return np.std(hsobel(image_array))\n",
      "\n",
      "def feature_20(image_array):\n",
      "    \"\"\" Returns the fraction of pixels above a threshold of the luminosity \n",
      "    for the horizontal edges map \"\"\"\n",
      "    thresh = 20 # Based on looking at histograms of edge maps of pictures\n",
      "    if len(image_array.shape) == 3:\n",
      "        image_array = image_array.mean(axis=2)\n",
      "    h_edge = hsobel(image_array)\n",
      "    return 1.0*sum((h_edge >= thresh).flatten())/h_edge.size\n",
      "\n",
      "def feature_21(image_array):\n",
      "    \"\"\" Returns the fraction of pixels above a threshold of the luminosity \n",
      "    for the vertical edges map \"\"\"\n",
      "    thresh = 20 # Based on looking at histograms of edge maps of pictures\n",
      "    if len(image_array.shape) == 3:\n",
      "        image_array = image_array.mean(axis=2)\n",
      "    v_edge = vsobel(image_array)\n",
      "    return 1.0*sum((v_edge >= thresh).flatten())/v_edge.size\n",
      "\n",
      "def feature_22(image_array):\n",
      "    \"\"\" Returns the aspect ratio of the image \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        image_array = image_array.mean(axis=2)\n",
      "    (height, width) = image_array.shape\n",
      "    return 1.0*height/width\n",
      "\n",
      "def feature_23(image_array):\n",
      "    \"\"\" Returns the number of image peaks \"\"\"\n",
      "    return len(plm(image_array, min_distance=50))\n",
      "#--------------------------------- End Features list ---------------------------------\n",
      "\n",
      "def collect_paths(imDirectory):\n",
      "    \"\"\" Given a validation directory, returns a list of image path strings for that directory.  Assumes\n",
      "        no sub-folders within the directory; just image files. \"\"\"\n",
      "    image_paths = []\n",
      "    image_names = listdir(imDirectory)\n",
      "    for name in image_names:\n",
      "        if name[0] != '.':\n",
      "            image_paths.append(imDirectory + \"/\" + name)\n",
      "        else:\n",
      "            print \"bad image '\" + name +\"' was skipped!\"\n",
      "    return (image_paths, image_names)\n",
      "\n",
      "def generate_feature_set(images_directory):\n",
      "    \"\"\" takes in the directory for the validation set, and creates / returns a feature set correctly\n",
      "        formatted for prediction by the classifier \"\"\"\n",
      "    image_paths = collect_paths(images_directory)\n",
      "    print \"\\t Now beginning rectangularization of validation images...\"\n",
      "    before_extraction = time()\n",
      "    features = extract_features(image_paths[0])\n",
      "    after_extraction = time()\n",
      "    print(\"\\nFeature extraction complete after {0:.2f} seconds, or {1:.4f} seconds per image, for {2:.0f} total images.\"\\\n",
      "          .format(after_extraction-before_extraction,(after_extraction-before_extraction)/float(len(image_paths[0])),\n",
      "                  len(image_paths[0])))\n",
      "    print(\"Feature set contains {0:.0f} instances, each with {1:.0f} extracted features.\"\\\n",
      "          .format(features.shape[0], features.shape[1]))\n",
      "    return (features, image_paths[1])\n",
      "\n",
      "#--------------------------------- Main Function ---------------------------------\n",
      "def run_final_classifier(path, forest=\"./trained_classifier.p\"):\n",
      "    \"\"\" Main function.  path = path to directory of validation images, forest = trained_classifier pickle,\n",
      "        generated from hw4_classifier_dev ipython notebook.  Creates a file with predictions of classes\n",
      "        of validation images \"\"\"\n",
      "    clf = pickle.load( open( forest, \"rb\" ) ) # load up the classifier\n",
      "    (X,val_images) = generate_feature_set(path) # generate feature set from the images\n",
      "    Y_pred = clf.predict(X)\n",
      "    \n",
      "    # Create output file\n",
      "    my_str = \"filename\" + \" \"*22 + \"predicted_class\\n\" + \\\n",
      "         \"---------------------------------------------\\n\"\n",
      "    for i, prediction in enumerate(Y_pred):\n",
      "        my_str += val_images[i] + \" \"*(30-len(val_images[i])) + prediction + \"\\n\"\n",
      "    with open(\"Output.txt\", \"w\") as text_file:\n",
      "        text_file.write(my_str)\n",
      "    print \"\\nSee the file 'Output.txt' for the classifier's predictions\"\n",
      "    \n",
      "    return (Y_pred, val_images)\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    print(\"Use the function: (predictions, file_names) = run_final_classifier(path, forest) to evaluate classifier on validation set\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Use the function: (predictions, file_names) = run_final_classifier(path, forest) to evaluate classifier on validation set\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(predictions, file_names) = run_final_classifier('/new/path/here')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    }
   ],
   "metadata": {}
  }
 ]
}