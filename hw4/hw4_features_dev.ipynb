{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from os import listdir\n",
      "import numpy as np\n",
      "import pickle\n",
      "from time import time\n",
      "\n",
      "num_categs = 20 # actual number of categories is one less than this b/c of \".DS_Store\"\n",
      "num_pics = 50\n",
      "\n",
      "MYDIRECTORY = '/Users/sean/Desktop/50_categories'\n",
      "\n",
      "image_paths = []\n",
      "image_names = []\n",
      "categories = listdir(MYDIRECTORY)\n",
      "for category in categories:#[:num_categs]:\n",
      "    if category[0] != '.':\n",
      "        image_names = listdir(MYDIRECTORY  + \"/\" + category)\n",
      "    else:\n",
      "        print \"bad category '\" + category +\"' was skipped!\"\n",
      "    for name in image_names:#[:num_pics]:\n",
      "        image_paths.append(MYDIRECTORY + \"/\" + category + \"/\" + name)\n",
      "np.random.shuffle(image_paths) # randomize the data set\n",
      "\n",
      "print \"\\t Now beginning Feature extraction...\"\n",
      "before_extraction = time()\n",
      "features = extract_features(image_paths)\n",
      "after_extraction = time()\n",
      "pickle.dump( features, open( \"extracted_features.p\", \"wb\" ) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "bad category '.DS_Store' was skipped!\n",
        "\t Now beginning Feature extraction..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Feature extraction complete after 950.685562134 seconds, or 0.22400696563 seconds per image, for 4244 images."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(4244, 19)\n",
        "['airplanes' 'bat' 'bear' 'blimp' 'camel' 'comet' 'conch' 'cormorant'\n",
        " 'crab' 'dog' 'dolphin' 'duck' 'elephant' 'elk' 'frog' 'galaxy' 'giraffe'\n",
        " 'goat' 'goldfish' 'goose' 'gorilla' 'helicopter' 'horse' 'hot-air-balloon'\n",
        " 'hummingbird' 'iguana' 'kangaroo' 'killer-whale' 'leopards' 'llama' 'mars'\n",
        " 'mussels' 'octopus' 'ostrich' 'owl' 'penguin' 'porcupine' 'raccoon'\n",
        " 'saturn' 'skunk' 'snail' 'snake' 'speed-boat' 'starfish' 'swan'\n",
        " 'teddy-bear' 'toad' 'triceratops' 'unicorn' 'zebra']\n"
       ]
      }
     ],
     "prompt_number": 357
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"Feature extraction complete after {0:.2f} seconds, or {1:.4f} seconds per image, for {2:.0f} total images.\"\\\n",
      "      .format(after_extraction-before_extraction,(after_extraction-before_extraction)/float(len(image_paths)),\n",
      "              len(image_paths)))\n",
      "print(\"Feature set contains {0:.0f} instances, each with {1:.0f} features.\".format(features[0].shape[0], features[0].shape[1]))\n",
      "print(\"Target contains {0:.0f} unique classes.\".format(len(np.unique(features[1]))))\n",
      "\n",
      "print(\"Feature extraction completion:\")\n",
      "for i in range(100):\n",
      "    print(\"{0:.0f}%...\".format(i)), "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Feature extraction complete after 950.69 seconds, or 0.2240 seconds per image, for 4244 total images.\n",
        "Feature set contains 4244 instances, each with 19 features.\n",
        "Target contains 50 unique classes.\n",
        "Feature extraction completion:\n",
        "0%... 1%... 2%... 3%... 4%... 5%... 6%... 7%... 8%... 9%... 10%... 11%... 12%... 13%... 14%... 15%... 16%... 17%... 18%... 19%... 20%... 21%... 22%... 23%... 24%... 25%... 26%... 27%... 28%... 29%... 30%... 31%... 32%... 33%... 34%... 35%... 36%... 37%... 38%... 39%... 40%... 41%... 42%... 43%... 44%... 45%... 46%... 47%... 48%... 49%... 50%... 51%... 52%... 53%... 54%... 55%... 56%... 57%... 58%... 59%... 60%... 61%... 62%... 63%... 64%... 65%... 66%... 67%... 68%... 69%... 70%... 71%... 72%... 73%... 74%... 75%... 76%... 77%... 78%... 79%... 80%... 81%... 82%... 83%... 84%... 85%... 86%... 87%... 88%... 89%... 90%... 91%... 92%... 93%... 94%... 95%... 96%... 97%... 98%... 99%...\n"
       ]
      }
     ],
     "prompt_number": 369
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TOY cell to practice making features\n",
      "#image_array = imread(image_paths[0]) # practice images\n",
      "#import matplotlib.pyplot as plt\n",
      "\n",
      "image_array = imread('/Users/sean/Desktop/50_categories/blimp/blimp_0023.jpg')\n",
      "\n",
      "a = [1,2,3,4,5,6,7]\n",
      "b = ['one','two','three','four']\n",
      "c = zip(a,b)\n",
      "print c\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(1, 'one'), (2, 'two'), (3, 'three'), (4, 'four')]\n"
       ]
      }
     ],
     "prompt_number": 354
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from os import listdir\n",
      "from multiprocessing import Pool, cpu_count\n",
      "from pylab import imread\n",
      "from time import time\n",
      "from skimage.filter import vsobel, hsobel\n",
      "\n",
      "def split_seq(seq, size):\n",
      "    \"\"\" Splits list \"seq\" into a list of \"size\" number of smaller, roughly equal length, lists \"\"\"\n",
      "    newseq = []\n",
      "    splitsize = 1.0/size*len(seq)\n",
      "    for i in range(size):\n",
      "        newseq.append(seq[int(round(i*splitsize)):\n",
      "            int(round((i+1)*splitsize))])\n",
      "    return newseq\n",
      "\n",
      "def extract_features(image_path_list):\n",
      "    feature_list = []\n",
      "    target_list = []\n",
      "    for image_path in image_path_list:\n",
      "        image_array = imread(image_path)\n",
      "        category = image_path.split('/')[-2]\n",
      "        target_list.append(category) # target = name of category\n",
      "        feature_list.append([feature_1(image_array), # image size\n",
      "                             feature_2(image_array), # mean red-channel\n",
      "                             feature_3(image_array), # mean green-channel\n",
      "                             feature_4(image_array), # mean blue-channel\n",
      "                             feature_5(image_array), # mean luminosity\n",
      "                             feature_6(image_array), # median luminosity\n",
      "                             feature_7(image_array), # standard deviation luminosity\n",
      "                             feature_8(image_array), # median red-channel\n",
      "                             feature_9(image_array), # median green-channel\n",
      "                             feature_10(image_array), # median blue-channel\n",
      "                             feature_11(image_array), # standard deviation red-channel\n",
      "                             feature_12(image_array), # standard deviation green-channel\n",
      "                             feature_13(image_array), # standard deviation blue-channel\n",
      "                             feature_14(image_array), # mean luminosity of vertical edge map\n",
      "                             feature_15(image_array), # median luminosity of vertical edge map\n",
      "                             feature_16(image_array), # standard deviation luminosity of vertical edge map\n",
      "                             feature_17(image_array), # mean luminosity of horizontal edge map\n",
      "                             feature_18(image_array), # median luminosity of horizontal edge map\n",
      "                             feature_19(image_array), # standard deviation luminosity of horizontal edge map\n",
      "                             ])\n",
      "    return ( np.array(feature_list), np.array(target_list) ) # easier indexing\n",
      "\n",
      "#----------------------- Features list -----------------------\n",
      "def feature_1(image_array):\n",
      "    \"\"\" Return the size of the image, in pixels \"\"\"\n",
      "    return image_array.size\n",
      "\n",
      "def feature_2(image_array):\n",
      "    \"\"\" Return the average red-channel value for the picture (in 0-255 scale) \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        return image_array[:,:,0].mean()\n",
      "    else:\n",
      "        return image_array.mean()\n",
      "\n",
      "def feature_3(image_array):\n",
      "    \"\"\" Return the average blue-channel value for the picture (in 0-255 scale) \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        return image_array[:,:,1].mean()\n",
      "    else:\n",
      "        return image_array.mean()\n",
      "\n",
      "def feature_4(image_array):\n",
      "    \"\"\" Return the average green-channel value for the picture (in 0-255 scale) \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        return image_array[:,:,2].mean()\n",
      "    else:\n",
      "        return image_array.mean()\n",
      "\n",
      "def feature_5(image_array):\n",
      "    \"\"\" Return the average luminosity value for the picture (in 0-255 scale) \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        return image_array.mean(axis=2).mean()\n",
      "    else:\n",
      "        return image_array.mean()\n",
      "\n",
      "def feature_6(image_array):\n",
      "    \"\"\" Returns the median pixels luminosity \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        image_array = image_array.mean(axis=2)\n",
      "    return np.median(image_array)\n",
      "\n",
      "def feature_7(image_array):\n",
      "    \"\"\" Returns the standard deviation of the pixels' luminosity \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        image_array = image_array.mean(axis=2)\n",
      "    return np.std(image_array)\n",
      "\n",
      "def feature_8(image_array):\n",
      "    \"\"\" Return the median red-channel value for the picture (in 0-255 scale) \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        return np.median(image_array[:,:,0])\n",
      "    else:\n",
      "        return np.median(image_array)\n",
      "\n",
      "def feature_9(image_array):\n",
      "    \"\"\" Return the median blue-channel value for the picture (in 0-255 scale) \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        return np.median(image_array[:,:,1])\n",
      "    else:\n",
      "        return np.median(image_array)\n",
      "\n",
      "def feature_10(image_array):\n",
      "    \"\"\" Return the median green-channel value for the picture (in 0-255 scale) \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        return np.median(image_array[:,:,2])\n",
      "    else:\n",
      "        return np.median(image_array)\n",
      "\n",
      "def feature_11(image_array):\n",
      "    \"\"\" Return the standard deviation of the red-channel value for the picture (in 0-255 scale) \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        return np.std(image_array[:,:,0])\n",
      "    else:\n",
      "        return np.std(image_array)\n",
      "\n",
      "def feature_12(image_array):\n",
      "    \"\"\" Return the the standard deviation of the blue-channel value for the picture (in 0-255 scale) \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        return np.std(image_array[:,:,1])\n",
      "    else:\n",
      "        return np.std(image_array)\n",
      "\n",
      "def feature_13(image_array):\n",
      "    \"\"\" Return the the standard deviation of the green-channel value for the picture (in 0-255 scale) \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        return np.std(image_array[:,:,2])\n",
      "    else:\n",
      "        return np.std(image_array)\n",
      "\n",
      "def feature_14(image_array):\n",
      "    \"\"\" Return the average luminosity for vertical edges map \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        image_array = image_array.mean(axis=2)\n",
      "    return np.mean(vsobel(image_array))\n",
      "\n",
      "def feature_15(image_array):\n",
      "    \"\"\" Returns the median luminosity for vertical edges map \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        image_array = image_array.mean(axis=2)\n",
      "    return np.median(vsobel(image_array))\n",
      "\n",
      "def feature_16(image_array):\n",
      "    \"\"\" Returns the standard deviation of the luminosity for vertical edges map \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        image_array = image_array.mean(axis=2)\n",
      "    return np.std(vsobel(image_array))\n",
      "\n",
      "def feature_17(image_array):\n",
      "    \"\"\" Return the average luminosity for horizontal edges map \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        image_array = image_array.mean(axis=2)\n",
      "    return np.mean(hsobel(image_array))\n",
      "\n",
      "def feature_18(image_array):\n",
      "    \"\"\" Returns the median luminosity for horizontal edges map \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        image_array = image_array.mean(axis=2)\n",
      "    return np.median(hsobel(image_array))\n",
      "\n",
      "def feature_19(image_array):\n",
      "    \"\"\" Returns the standard deviation of the luminosity for horizontal edges map \"\"\"\n",
      "    if len(image_array.shape) == 3:\n",
      "        image_array = image_array.mean(axis=2)\n",
      "    return np.std(hsobel(image_array))\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 329
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Main program starts here ###################################################\n",
      "# We first collect all the local paths to all the images in one list\n",
      "image_paths = []\n",
      "categories = listdir(MYDIRECTORY)\n",
      "for category in categories:\n",
      "    image_names = listdir(MYDIRECTORY  + \"/\" + category)\n",
      "    for name in image_names:\n",
      "        image_paths.append(MYDIRECTORY + \"/\" + category + \"/\" + name)\n",
      "\n",
      "print (\"There should be 4244 images, actual number is \" + \n",
      "    str(len(image_paths)) + \".\")\n",
      "\n",
      "# Then, we run the feature extraction function using multiprocessing.Pool so \n",
      "# so that we can parallelize the process and run it much faster.\n",
      "numprocessors = cpu_count() # To see results of parallelizing, set numprocessors\n",
      "                            # to less than cpu_count().\n",
      "# numprocessors = 1\n",
      "\n",
      "# We have to cut up the image_paths list into the number of processes we want to\n",
      "# run. \n",
      "split_image_paths = split_seq(image_paths, numprocessors)\n",
      "\n",
      "# Ok, this block is where the parallel code runs. We time it so we can get a \n",
      "# feel for the speed up.\n",
      "start_time = time()\n",
      "p = Pool(numprocessors)\n",
      "result = p.map_async(extract_features, split_image_paths)\n",
      "poolresult = result.get()\n",
      "end_time = time()\n",
      "\n",
      "# All done, print timing results.\n",
      "print (\"Finished extracting features. Total time: \" + \n",
      "    str(round(end_time-start_time, 3)) + \" s, or \" + \n",
      "    str( round( (end_time-start_time)/len(image_paths), 5 ) ) + \" s/image.\")\n",
      "# This took about 10-11 seconds on my 2.2 GHz, Core i7 MacBook Pro. It may also\n",
      "# be affected by hard disk read speeds.\n",
      "\n",
      "# To tidy-up a bit, we loop through the poolresult to create a final list of\n",
      "# the feature extraction results for all images.\n",
      "combined_result = []\n",
      "for single_proc_result in poolresult:\n",
      "    for single_image_result in single_proc_result:\n",
      "        combined_result.append(single_image_result)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}