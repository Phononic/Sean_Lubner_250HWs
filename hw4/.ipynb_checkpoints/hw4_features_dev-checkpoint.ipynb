{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from os import listdir\n",
      "\n",
      "image_paths = []\n",
      "practice_path = '/Users/sean/Desktop/50_categories/airplanes'\n",
      "image_names = listdir(practice_path)\n",
      "image_names = image_names[:2]\n",
      "for name in image_names:\n",
      "    image_paths.append(practice_path + \"/\" + name)\n",
      "\n",
      "toy = imread(image_paths[0]) # practice images\n",
      "features = extract_features(image_paths)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Helper code from: Christopher Klein, Joshua Bloom\n",
      "\"\"\"\n",
      "from os import listdir\n",
      "from multiprocessing import Pool, cpu_count\n",
      "from pylab import imread\n",
      "from time import time\n",
      "\n",
      "MYDIRECTORY = \"/Users/sean/Desktop/50_-categories\" # so not accidentally run, remove the '-'\n",
      "\n",
      "def split_seq(seq, size):\n",
      "    \"\"\" Splits list \"seq\" into a list of \"size\" number of smaller, roughly equal length, lists \"\"\"\n",
      "    newseq = []\n",
      "    splitsize = 1.0/size*len(seq)\n",
      "    for i in range(size):\n",
      "        newseq.append(seq[int(round(i*splitsize)):\n",
      "            int(round((i+1)*splitsize))])\n",
      "    return newseq\n",
      "# Our simple feature extraction function. It takes in a list of image paths, \n",
      "# does some measurement on each image, then returns a list of the image paths\n",
      "# paired with the results of the feature measurement.\n",
      "def extract_features(image_path_list):\n",
      "    feature_list = []\n",
      "    for image_path in image_path_list:\n",
      "        image_array = imread(image_path)\n",
      "        feature_list.append([image_path,\n",
      "                             feature_1(image_array), # image size\n",
      "                             feature_2(image_array), # mean red-channel\n",
      "                             feature_3(image_array), # mean green-channel\n",
      "                             feature_4(image_array), # mean blue-channel\n",
      "                             feature_5(image_array) # mean luminosity\n",
      "                             ])\n",
      "    return feature_list\n",
      "\n",
      "# Features list\n",
      "def feature_1(image_array):\n",
      "    \"\"\" Return the size of the image, in pixels \"\"\"\n",
      "    return image_array.size\n",
      "\n",
      "def feature_2(image_array):\n",
      "    \"\"\" Return the average red-channel value for the picture (in 0-255 scale) \"\"\"\n",
      "    return image_array[:,:,0].mean()\n",
      "\n",
      "def feature_3(image_array):\n",
      "    \"\"\" Return the average blue-channel value for the picture (in 0-255 scale) \"\"\"\n",
      "    return image_array[:,:,1].mean()\n",
      "\n",
      "def feature_4(image_array):\n",
      "    \"\"\" Return the average green-channel value for the picture (in 0-255 scale) \"\"\"\n",
      "    return image_array[:,:,2].mean()\n",
      "\n",
      "def feature_5(image_array):\n",
      "    \"\"\" Return the average luminosity value for the picture (in 0-255 scale) \"\"\"\n",
      "    return image_array.mean(axis=2).mean()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Main program starts here ###################################################\n",
      "# We first collect all the local paths to all the images in one list\n",
      "image_paths = []\n",
      "categories = listdir(MYDIRECTORY)\n",
      "for category in categories:\n",
      "    image_names = listdir(MYDIRECTORY  + \"/\" + category)\n",
      "    for name in image_names:\n",
      "        image_paths.append(MYDIRECTORY + \"/\" + category + \"/\" + name)\n",
      "\n",
      "print (\"There should be 4244 images, actual number is \" + \n",
      "    str(len(image_paths)) + \".\")\n",
      "\n",
      "# Then, we run the feature extraction function using multiprocessing.Pool so \n",
      "# so that we can parallelize the process and run it much faster.\n",
      "numprocessors = cpu_count() # To see results of parallelizing, set numprocessors\n",
      "                            # to less than cpu_count().\n",
      "# numprocessors = 1\n",
      "\n",
      "# We have to cut up the image_paths list into the number of processes we want to\n",
      "# run. \n",
      "split_image_paths = split_seq(image_paths, numprocessors)\n",
      "\n",
      "# Ok, this block is where the parallel code runs. We time it so we can get a \n",
      "# feel for the speed up.\n",
      "start_time = time()\n",
      "p = Pool(numprocessors)\n",
      "result = p.map_async(extract_features, split_image_paths)\n",
      "poolresult = result.get()\n",
      "end_time = time()\n",
      "\n",
      "# All done, print timing results.\n",
      "print (\"Finished extracting features. Total time: \" + \n",
      "    str(round(end_time-start_time, 3)) + \" s, or \" + \n",
      "    str( round( (end_time-start_time)/len(image_paths), 5 ) ) + \" s/image.\")\n",
      "# This took about 10-11 seconds on my 2.2 GHz, Core i7 MacBook Pro. It may also\n",
      "# be affected by hard disk read speeds.\n",
      "\n",
      "# To tidy-up a bit, we loop through the poolresult to create a final list of\n",
      "# the feature extraction results for all images.\n",
      "combined_result = []\n",
      "for single_proc_result in poolresult:\n",
      "    for single_image_result in single_proc_result:\n",
      "        combined_result.append(single_image_result)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}